TODO
----
- Add configuration flags to start with multiple shards and API workers
- Implement performance test suite using Locust or similar to measure the performance
  impact between new and old implementation.
- Add integration test suite that runs against running process(es) to verify that interprocess
  communication works.
- Add measurements and metrics to the different parts of the processing that are returned as
  a header in the response.
- Implement L2 cache and measure efficiency
- Share more code between non-sharded and sharded implementation and move the pieces that
  differ into a connector.


 Query
 -----
 - Input
   * Dataset key
   * Query
   * Filter engine
   * Stand in columns
   * Accept type
- Output
   * Status ("Success", "Malformed query", "Not found")
   * Data (data or error details) serialized according to
     accept type.
   * Unsliced length
   * Content type
   * Stats

Insert
------
- Input
   * Key
   * Content type
   * Content
   * Stand in columns

- Output
   * Status ("Success", "Error")

Delete
------
- Input
   * Key

- Output, non needed really

Statistics
----------
- Input

- Output
   * Statistics dict


Semantic differences
--------------------
- Sub select handling of NaN values. Previously used to
  include NaNs. Now it does not. This is more inline with
  SQL.
- Python 3. Aliases cannot be set to strings for the moment
  this may change in the future to be possible again.